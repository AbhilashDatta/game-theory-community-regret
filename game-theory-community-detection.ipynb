{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-22T00:49:51.463172Z","iopub.execute_input":"2021-08-22T00:49:51.463483Z","iopub.status.idle":"2021-08-22T00:49:51.479513Z","shell.execute_reply.started":"2021-08-22T00:49:51.463457Z","shell.execute_reply":"2021-08-22T00:49:51.478378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import networkx as nx\nimport community\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics.cluster import normalized_mutual_info_score\n","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-08-22T00:49:54.303809Z","iopub.execute_input":"2021-08-22T00:49:54.304239Z","iopub.status.idle":"2021-08-22T00:49:54.30922Z","shell.execute_reply.started":"2021-08-22T00:49:54.304201Z","shell.execute_reply":"2021-08-22T00:49:54.308069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Main Code\n\ndef utility(node_i,S, G):\n    total_utility = 0\n    k_i = G.degree[node_i]\n    for node_j in S:\n        if node_i != node_j:\n            curr_edges = A[node_i][node_j]\n\n            k_j = G.degree[node_j]\n            m = G.number_of_edges()\n            degree_prod = (k_i*k_j)/(2.0*m)\n\n            indiv_utility = curr_edges - degree_prod\n            total_utility += indiv_utility\n    return total_utility\n\n\ndef internalCommunityEdges(nodes_list, community_label):\n    internaledges = 0\n    for node in nodes_list:\n        p = len(np.where(S[[n for n in G.neighbors(node)]] == community_label)[0])\n        #print(node)\n        internaledges += p\n    \n    inter = internaledges/(2.0)\n    return inter\n\n\ndef community_ext(nodes_list):\n    unique_external_nodes = []\n    total_sum = 0\n    community_label = S[nodes_list[0]]\n    total_connections = 0\n    totalExternalNodeDegree = 0\n    for nod in nodes_list:\n        #neighbors of node in that community       \n        for neig in G[nod]:\n            # external node\n            if S[neig] != S[nod]:\n                if neig not in unique_external_nodes:\n                    unique_external_nodes.append(neig)\n                total_connections += 1\n                \n    communityDegree = len(unique_external_nodes)\n    for externalNode in unique_external_nodes:\n        totalExternalNodeDegree += G.degree(externalNode)\n        \n    \n    totalCommunityEdges = totalEdges - internalCommunityEdges(nodes_list, community_label)\n    modularityComm = total_connections - ((totalExternalNodeDegree*communityDegree)/(2.0 * totalCommunityEdges))\n    modularityComm = modularityComm/(2.0 * totalCommunityEdges)\n    return modularityComm\n\n\ndef join(node_i,S, G, lamda, probabilities):\n    max_utility = []\n    community_toJoin = []\n    currentCommunity = S[node_i]\n    currentCommunity_nodes_list = np.where(S == currentCommunity)[0]\n    \n    loss = utility(node_i, currentCommunity_nodes_list, G)\n    #print(loss)\n    for neighbor in G[node_i]:\n        community_label = S[neighbor]\n        community_toJoin.append(community_label)\n        nodes_list = np.where(S == community_label)[0]\n        gain = utility(node_i, nodes_list, G)\n        \n        community_label = S[neighbor]\n#         print(community_label)\n        #community_toJoin.append(community_label)\n        same_community_nodes_list = np.where(S == community_label)[0]\n        other = community_ext(same_community_nodes_list)\n        val = lamda*(gain-loss) + (1-lamda)*(other)\n        max_utility.append(val)\n        #print(nodes_list)\n    \n    maximum_utility_val = max(max_utility)\n    if(maximum_utility_val) >0:\n        probabilities[node_i] *= (1-lamda)\n    maxUtilityIndex = max_utility.index(maximum_utility_val)\n    communityIndex = community_toJoin[maxUtilityIndex]\n    #print(communityIndex)\n    \n    #update the community for node_i\n    S[node_i] = communityIndex\n    return S\n\n\nfrom sklearn.metrics.cluster import normalized_mutual_info_score\n\ndef partitionModularity(mod_list,G):\n    totalModularity = 0\n    for node_i in range(G.number_of_nodes()):\n        totalModularity += utility(node_i,np.where(mod_list==mod_list[node_i])[0],G)\n    return (totalModularity/(G.number_of_edges()*2.0))\n\nfrom tqdm.auto import tqdm\n\ndef communityDetect(S,G, nIter, LAMBDA = 1):\n    total_nodes = G.number_of_nodes()\n    i = 0\n    prev_S = initial_S\n    val = []\n#   while(i<nIter):\n    for _ in tqdm(range(nIter)):\n#         print(\"Iteration No. : \", i+1)\n        probab = np.array(probabilities)\n        probab /= probab.sum()\n        random_node = choice(nodesList, 1, p=probab)\n        S = join(random_node[0], S, G, LAMBDA, probab)\n        val.append(partitionModularity(S,G))\n        prev_S = S      \n#         i += 1\n        \n    return val, prev_S\n        ","metadata":{"execution":{"iopub.status.busy":"2021-08-22T00:49:54.590297Z","iopub.execute_input":"2021-08-22T00:49:54.590589Z","iopub.status.idle":"2021-08-22T00:49:54.614349Z","shell.execute_reply.started":"2021-08-22T00:49:54.590566Z","shell.execute_reply":"2021-08-22T00:49:54.612997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Baselines","metadata":{}},{"cell_type":"markdown","source":"# CommunityGAN","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/SamJia/CommunityGAN.git","metadata":{"execution":{"iopub.status.busy":"2021-08-22T00:39:38.093311Z","iopub.execute_input":"2021-08-22T00:39:38.093642Z","iopub.status.idle":"2021-08-22T00:39:40.171897Z","shell.execute_reply.started":"2021-08-22T00:39:38.093584Z","shell.execute_reply":"2021-08-22T00:39:40.170215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import subprocess\nimport os\n\n\n\nif not os.path.exists('./CommunityGAN/src/PreTrain/community_detection'):\n    os.makedirs('./CommunityGAN/src/PreTrain/community_detection')\n\nsubprocess.call('./magic -i ../input/biodmlc/bio-DM-LC.txt  -o ./CommunityGAN/pre_train/community_detection/biodmlc_ -nt 20 -c 100 -mi 200', shell=True, cwd='./CommunityGAN/src/PreTrain/')\nsubprocess.call('python format_transform.py ./CommunityGAN/src/PreTrain/community_detection/bio-DM-LC_final.f.txt ./CommunityGAN/pre_train/community_detection/biodmlc_pre_train.emb', shell=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-22T00:53:39.675446Z","iopub.execute_input":"2021-08-22T00:53:39.675764Z","iopub.status.idle":"2021-08-22T00:53:39.822305Z","shell.execute_reply.started":"2021-08-22T00:53:39.675739Z","shell.execute_reply":"2021-08-22T00:53:39.820765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subprocess.call('python community_gan.py dataset biodmlc n_emb 100 motif_size 3', shell=True, cwd='./CommunityGAN/src/CommunityGAN/')","metadata":{"execution":{"iopub.status.busy":"2021-08-22T00:53:41.547733Z","iopub.execute_input":"2021-08-22T00:53:41.548106Z","iopub.status.idle":"2021-08-22T00:53:44.680519Z","shell.execute_reply.started":"2021-08-22T00:53:41.548075Z","shell.execute_reply":"2021-08-22T00:53:44.679118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Our Model","metadata":{}},{"cell_type":"markdown","source":"# Bio DM-LC Dataset","metadata":{}},{"cell_type":"code","source":"import networkx as nx\nimport pandas as pd\n\nl1 = []\nl2 = []\nfile = open('../input/biodmlc/bio-DM-LC.txt')\n\nfor line in file:\n    l1.append(int(line.split()[0]))\n    l2.append(int(line.split()[1]))\n\ndf = pd.DataFrame()\ndf[1] = l1\ndf[2] = l2\n\nG = nx.Graph()\nG = nx.from_pandas_edgelist(df, 1, 2)\n\nmapping  = {} \ni = 0\nfor node in G.nodes:\n    mapping[node] = i\n    i += 1\n    \n    \nG=nx.relabel_nodes(G,mapping)\n\nprint(nx.info(G))","metadata":{"execution":{"iopub.status.busy":"2021-08-18T02:55:57.403148Z","iopub.execute_input":"2021-08-18T02:55:57.403755Z","iopub.status.idle":"2021-08-18T02:55:57.445452Z","shell.execute_reply.started":"2021-08-18T02:55:57.403707Z","shell.execute_reply":"2021-08-18T02:55:57.444312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"part = community.best_partition(G)\ncommunity.modularity(part, G)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T02:55:59.487132Z","iopub.execute_input":"2021-08-18T02:55:59.487483Z","iopub.status.idle":"2021-08-18T02:55:59.597795Z","shell.execute_reply.started":"2021-08-18T02:55:59.487438Z","shell.execute_reply":"2021-08-18T02:55:59.596806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nfrom random import choice\nimport random\n\ntotalEdges = G.number_of_edges()\ntotalNodes= G.number_of_nodes()\nA = nx.to_numpy_array(G)\nS = np.array([(\"C\" + str(i)) for i in range(G.number_of_nodes())])\n\ninitial_S = np.array([(\"C\" + str(i)) for i in range(G.number_of_nodes())])\nnodesList = [node_k for node_k in range(G.number_of_nodes())]\n\nfrom numpy.random import choice\nprobabilities = [float(1/(G.number_of_nodes()*1.0)) for i in range(G.number_of_nodes())]\n\nvalue_lambda_point2 = communityDetect(S,G,nIter = 1000,LAMBDA = 0.2)\n\nprint('Partition Modularity = '+ str(partitionModularity(S,G)))","metadata":{"execution":{"iopub.status.busy":"2021-08-18T03:03:53.28178Z","iopub.execute_input":"2021-08-18T03:03:53.282208Z","iopub.status.idle":"2021-08-18T03:10:08.231443Z","shell.execute_reply.started":"2021-08-18T03:03:53.282172Z","shell.execute_reply":"2021-08-18T03:10:08.230764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nfrom random import choice\nimport random\n\ntotalEdges = G.number_of_edges()\ntotalNodes= G.number_of_nodes()\nA = nx.to_numpy_array(G)\nS = np.array([(\"C\" + str(i)) for i in range(G.number_of_nodes())])\ninitial_S = np.array([(\"C\" + str(i)) for i in range(G.number_of_nodes())])\nnodesList = [node_k for node_k in range(G.number_of_nodes())]\n\nfrom numpy.random import choice\nprobabilities = [float(1/(G.number_of_nodes()*1.0)) for i in range(G.number_of_nodes())]\n\nvalue_lambda_point8 = communityDetect(S,G,nIter = 1000,LAMBDA = 0.8)\n\nprint('Partition Modularity = '+ str(partitionModularity(S, G)))","metadata":{"execution":{"iopub.status.busy":"2021-08-18T03:14:24.926014Z","iopub.execute_input":"2021-08-18T03:14:24.926366Z","iopub.status.idle":"2021-08-18T03:21:41.063143Z","shell.execute_reply.started":"2021-08-18T03:14:24.926339Z","shell.execute_reply":"2021-08-18T03:21:41.061926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nfrom random import choice\nimport random\n\ntotalEdges = G.number_of_edges()\ntotalNodes= G.number_of_nodes()\nA = nx.to_numpy_array(G)\nS = np.array([(\"C\" + str(i)) for i in range(G.number_of_nodes())])\ninitial_S = np.array([(\"C\" + str(i)) for i in range(G.number_of_nodes())])\nnodesList = [node_k for node_k in range(G.number_of_nodes())]\n\nfrom numpy.random import choice\nprobabilities = [float(1/(G.number_of_nodes()*1.0)) for i in range(G.number_of_nodes())]\n\nvalue_lambda_1 = communityDetect(S,G,nIter = 1000,LAMBDA = 1)\n\nprint('Partition Modularity = '+ str(partitionModularity(S, G)))","metadata":{"execution":{"iopub.status.busy":"2021-08-18T03:22:26.204504Z","iopub.execute_input":"2021-08-18T03:22:26.204873Z","iopub.status.idle":"2021-08-18T03:27:41.286387Z","shell.execute_reply.started":"2021-08-18T03:22:26.204845Z","shell.execute_reply":"2021-08-18T03:27:41.285479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns \n\nplt.style.use('fivethirtyeight')\n%config InlineBackend.figure_format = 'retina'\n%matplotlib inline\n\nsns.set(style = 'whitegrid')\nplt.title(\"Bio-DM-LC Dataset\")\nsns.lineplot([i for i in range(len(value_lambda_point2[0]))] , value_lambda_point2[0],  label=\"lambda 0.2\")\nsns.lineplot([i for i in range(len(value_lambda_point8[0]))] , value_lambda_point8[0],  label=\"lambda 0.8\")\n \nplt.xlabel(\"No. of iterations\")\nplt.ylabel(\"Modularity Value\")\nplt.legend() \n# plt.show()\nplt.savefig(\"Bio-DM-LC_1.svg\")","metadata":{"execution":{"iopub.status.busy":"2021-08-18T03:30:27.111308Z","iopub.execute_input":"2021-08-18T03:30:27.111688Z","iopub.status.idle":"2021-08-18T03:30:27.796088Z","shell.execute_reply.started":"2021-08-18T03:30:27.111655Z","shell.execute_reply":"2021-08-18T03:30:27.795341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns \n\nplt.style.use('fivethirtyeight')\n%config InlineBackend.figure_format = 'retina'\n%matplotlib inline\n\nsns.set(style = 'whitegrid')\nplt.title(\"Bio-DM-LC Dataset\")\nsns.lineplot([i for i in range(len(value_lambda_1[0]))] , value_lambda_1[0],  label=\"lambda 1\")\nsns.lineplot([i for i in range(len(value_lambda_point8[0]))] , value_lambda_point8[0],  label=\"lambda 0.8\")\n \nplt.xlabel(\"No. of iterations\")\nplt.ylabel(\"Modularity Value\")\nplt.legend() \n# plt.show()\nplt.savefig(\"Bio-DM-LC_2.svg\")","metadata":{"execution":{"iopub.status.busy":"2021-08-18T03:30:35.552896Z","iopub.execute_input":"2021-08-18T03:30:35.553316Z","iopub.status.idle":"2021-08-18T03:30:36.235232Z","shell.execute_reply.started":"2021-08-18T03:30:35.553281Z","shell.execute_reply":"2021-08-18T03:30:36.234197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Enron Dataset","metadata":{}},{"cell_type":"code","source":"import networkx as nx\nimport pandas as pd\n\nl1 = []\nl2 = []\nfile = open('../input/enrondata/ia-enron-only.txt')\n\nfor line in file:\n    l1.append(int(line.split()[0]))\n    l2.append(int(line.split()[1]))\n\ndf = pd.DataFrame()\ndf[1] = l1\ndf[2] = l2\n\nG = nx.Graph()\nG = nx.from_pandas_edgelist(df, 1, 2)\n\nmapping  = {} \ni = 0\nfor node in G.nodes:\n    mapping[node] = i\n    i += 1\n    \n    \nG=nx.relabel_nodes(G,mapping)\n\nprint(nx.info(G))","metadata":{"execution":{"iopub.status.busy":"2021-08-18T03:30:46.274303Z","iopub.execute_input":"2021-08-18T03:30:46.274665Z","iopub.status.idle":"2021-08-18T03:30:46.30593Z","shell.execute_reply.started":"2021-08-18T03:30:46.274631Z","shell.execute_reply":"2021-08-18T03:30:46.304898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"part = community.best_partition(G)\ncommunity.modularity(part, G)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T03:30:47.677135Z","iopub.execute_input":"2021-08-18T03:30:47.677497Z","iopub.status.idle":"2021-08-18T03:30:47.725606Z","shell.execute_reply.started":"2021-08-18T03:30:47.677469Z","shell.execute_reply":"2021-08-18T03:30:47.724819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from random import choice\nimport random\nimport numpy as np\n\ntotalEdges = G.number_of_edges()\ntotalNodes= G.number_of_nodes()\nA = nx.to_numpy_array(G)\nS = np.array([(\"C\" + str(i)) for i in range(G.number_of_nodes())])\n\ninitial_S = np.array([(\"C\" + str(i)) for i in range(G.number_of_nodes())])\nnodesList = [node_k for node_k in range(G.number_of_nodes())]\n\nfrom numpy.random import choice\nprobabilities = [float(1/(G.number_of_nodes()*1.0)) for i in range(G.number_of_nodes())]\n\nvalue_lambda_point2 = communityDetect(S,G,nIter = 1000,LAMBDA = 0.2)\n\nprint('Partition Modularity = '+ str(partitionModularity(S,G)))","metadata":{"execution":{"iopub.status.busy":"2021-08-18T03:30:48.979949Z","iopub.execute_input":"2021-08-18T03:30:48.980397Z","iopub.status.idle":"2021-08-18T03:32:52.395619Z","shell.execute_reply.started":"2021-08-18T03:30:48.980368Z","shell.execute_reply":"2021-08-18T03:32:52.394363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from random import choice\nimport random\n\ntotalEdges = G.number_of_edges()\ntotalNodes= G.number_of_nodes()\nA = nx.to_numpy_array(G)\nS = np.array([(\"C\" + str(i)) for i in range(G.number_of_nodes())])\n\ninitial_S = np.array([(\"C\" + str(i)) for i in range(G.number_of_nodes())])\nnodesList = [node_k for node_k in range(G.number_of_nodes())]\n\nfrom numpy.random import choice\nprobabilities = [float(1/(G.number_of_nodes()*1.0)) for i in range(G.number_of_nodes())]\n\nvalue_lambda_point8 = communityDetect(S,G,nIter = 1000,LAMBDA = 0.8)\n\nprint('Partition Modularity = '+ str(partitionModularity(S,G)))","metadata":{"execution":{"iopub.status.busy":"2021-08-18T03:36:16.538159Z","iopub.execute_input":"2021-08-18T03:36:16.538518Z","iopub.status.idle":"2021-08-18T03:38:19.348937Z","shell.execute_reply.started":"2021-08-18T03:36:16.538488Z","shell.execute_reply":"2021-08-18T03:38:19.348082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from random import choice\nimport random\n\ntotalEdges = G.number_of_edges()\ntotalNodes= G.number_of_nodes()\nA = nx.to_numpy_array(G)\nS = np.array([(\"C\" + str(i)) for i in range(G.number_of_nodes())])\n\ninitial_S = np.array([(\"C\" + str(i)) for i in range(G.number_of_nodes())])\nnodesList = [node_k for node_k in range(G.number_of_nodes())]\n\nfrom numpy.random import choice\nprobabilities = [float(1/(G.number_of_nodes()*1.0)) for i in range(G.number_of_nodes())]\n\nvalue_lambda_1 = communityDetect(S,G,nIter = 1000,LAMBDA = 1)\n\nprint('Partition Modularity = '+ str(partitionModularity(S,G)))","metadata":{"execution":{"iopub.status.busy":"2021-08-18T03:38:19.350886Z","iopub.execute_input":"2021-08-18T03:38:19.351197Z","iopub.status.idle":"2021-08-18T03:40:10.188887Z","shell.execute_reply.started":"2021-08-18T03:38:19.351164Z","shell.execute_reply":"2021-08-18T03:40:10.1878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns \n\nplt.style.use('fivethirtyeight')\n%config InlineBackend.figure_format = 'retina'\n%matplotlib inline\n\nsns.set(style = 'whitegrid')\nplt.title(\"Enron Dataset\")\nsns.lineplot([i for i in range(len(value_lambda_point2[0]))] , value_lambda_point2[0],  label=\"lambda 0.2\")\nsns.lineplot([i for i in range(len(value_lambda_point8[0]))] , value_lambda_point8[0],  label=\"lambda 0.8\")\n \nplt.xlabel(\"No. of iterations\")\nplt.ylabel(\"Modularity Value\")\nplt.legend() \n# plt.show()\nplt.savefig(\"Enron_1.svg\")","metadata":{"execution":{"iopub.status.busy":"2021-08-18T03:40:14.64664Z","iopub.execute_input":"2021-08-18T03:40:14.646995Z","iopub.status.idle":"2021-08-18T03:40:15.329962Z","shell.execute_reply.started":"2021-08-18T03:40:14.646966Z","shell.execute_reply":"2021-08-18T03:40:15.329084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns \n\nplt.style.use('fivethirtyeight')\n%config InlineBackend.figure_format = 'retina'\n%matplotlib inline\n\nsns.set(style = 'whitegrid')\nplt.title(\"Enron Dataset\")\nsns.lineplot([i for i in range(len(value_lambda_1[0]))] , value_lambda_1[0],  label=\"lambda 1\")\nsns.lineplot([i for i in range(len(value_lambda_point8[0]))] , value_lambda_point8[0],  label=\"lambda 0.8\")\n \nplt.xlabel(\"No. of iterations\")\nplt.ylabel(\"Modularity Value\")\nplt.legend() \n# plt.show()\nplt.savefig(\"Enron_2.svg\")","metadata":{"execution":{"iopub.status.busy":"2021-08-18T03:40:23.226169Z","iopub.execute_input":"2021-08-18T03:40:23.226527Z","iopub.status.idle":"2021-08-18T03:40:23.913012Z","shell.execute_reply.started":"2021-08-18T03:40:23.226499Z","shell.execute_reply":"2021-08-18T03:40:23.911966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Econ wm1 dataset","metadata":{}},{"cell_type":"code","source":"import networkx as nx\nimport pandas as pd\n\nl1 = []\nl2 = []\nfile = open('../input/econwm1/econ-wm1.txt')\n\nfor line in file:\n    l1.append(int(line.split()[0]))\n    l2.append(int(line.split()[1]))\n\ndf = pd.DataFrame()\ndf[1] = l1\ndf[2] = l2\n\nG = nx.Graph()\nG = nx.from_pandas_edgelist(df, 1, 2)\n\nmapping  = {} \ni = 0\nfor node in G.nodes:\n    mapping[node] = i\n    i += 1\n    \n    \nG=nx.relabel_nodes(G,mapping)\n\nprint(nx.info(G))","metadata":{"execution":{"iopub.status.busy":"2021-08-18T03:40:29.66082Z","iopub.execute_input":"2021-08-18T03:40:29.661204Z","iopub.status.idle":"2021-08-18T03:40:29.709539Z","shell.execute_reply.started":"2021-08-18T03:40:29.661176Z","shell.execute_reply":"2021-08-18T03:40:29.708612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"part = community.best_partition(G)\ncommunity.modularity(part, G)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T03:40:31.333454Z","iopub.execute_input":"2021-08-18T03:40:31.333793Z","iopub.status.idle":"2021-08-18T03:40:31.424439Z","shell.execute_reply.started":"2021-08-18T03:40:31.333764Z","shell.execute_reply":"2021-08-18T03:40:31.423569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from random import choice\nimport random\nimport numpy as np\n\ntotalEdges = G.number_of_edges()\ntotalNodes= G.number_of_nodes()\nA = nx.to_numpy_array(G)\nS = np.array([(\"C\" + str(i)) for i in range(G.number_of_nodes())])\n\ninitial_S = np.array([(\"C\" + str(i)) for i in range(G.number_of_nodes())])\nnodesList = [node_k for node_k in range(G.number_of_nodes())]\n\nfrom numpy.random import choice\nprobabilities = [float(1/(G.number_of_nodes()*1.0)) for i in range(G.number_of_nodes())]\n\nvalue_lambda_point2 = communityDetect(S,G,nIter = 600,LAMBDA = 0.2)\n\nprint('Partition Modularity = '+ str(partitionModularity(S,G)))","metadata":{"execution":{"iopub.status.busy":"2021-08-18T03:56:17.335414Z","iopub.execute_input":"2021-08-18T03:56:17.335798Z","iopub.status.idle":"2021-08-18T04:00:18.695245Z","shell.execute_reply.started":"2021-08-18T03:56:17.335749Z","shell.execute_reply":"2021-08-18T04:00:18.694221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom random import choice\nimport random\n\ntotalEdges = G.number_of_edges()\ntotalNodes= G.number_of_nodes()\nA = nx.to_numpy_array(G)\nS = np.array([(\"C\" + str(i)) for i in range(G.number_of_nodes())])\n\ninitial_S = np.array([(\"C\" + str(i)) for i in range(G.number_of_nodes())])\nnodesList = [node_k for node_k in range(G.number_of_nodes())]\n\nfrom numpy.random import choice\nprobabilities = [float(1/(G.number_of_nodes()*1.0)) for i in range(G.number_of_nodes())]\n\nvalue_lambda_point8 = communityDetect(S,G,nIter = 600,LAMBDA = 0.8)\n\nprint('Partition Modularity = '+ str(partitionModularity(S,G)))","metadata":{"execution":{"iopub.status.busy":"2021-08-18T04:00:18.696818Z","iopub.execute_input":"2021-08-18T04:00:18.697066Z","iopub.status.idle":"2021-08-18T04:02:45.675827Z","shell.execute_reply.started":"2021-08-18T04:00:18.697042Z","shell.execute_reply":"2021-08-18T04:02:45.674914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from random import choice\nimport random\n\ntotalEdges = G.number_of_edges()\ntotalNodes= G.number_of_nodes()\nA = nx.to_numpy_array(G)\nS = np.array([(\"C\" + str(i)) for i in range(G.number_of_nodes())])\n\ninitial_S = np.array([(\"C\" + str(i)) for i in range(G.number_of_nodes())])\nnodesList = [node_k for node_k in range(G.number_of_nodes())]\n\nfrom numpy.random import choice\nprobabilities = [float(1/(G.number_of_nodes()*1.0)) for i in range(G.number_of_nodes())]\n\nvalue_lambda_1 = communityDetect(S,G,nIter = 600,LAMBDA = 1)\n\nprint('Partition Modularity = '+ str(partitionModularity(S,G)))","metadata":{"execution":{"iopub.status.busy":"2021-08-18T04:02:45.677058Z","iopub.execute_input":"2021-08-18T04:02:45.677329Z","iopub.status.idle":"2021-08-18T04:05:02.828688Z","shell.execute_reply.started":"2021-08-18T04:02:45.677301Z","shell.execute_reply":"2021-08-18T04:05:02.827649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns \n\nplt.style.use('fivethirtyeight')\n%config InlineBackend.figure_format = 'retina'\n%matplotlib inline\n\nsns.set(style = 'whitegrid')\nplt.title(\"Econ-wm1 Dataset\")\nsns.lineplot([i for i in range(len(value_lambda_point2[0]))] , value_lambda_point2[0],  label=\"lambda 0.2\")\nsns.lineplot([i for i in range(len(value_lambda_point8[0]))] , value_lambda_point8[0],  label=\"lambda 0.8\")\n \nplt.xlabel(\"No. of iterations\")\nplt.ylabel(\"Modularity Value\")\nplt.legend() \n# plt.show()\nplt.savefig(\"Econ_1.svg\")","metadata":{"execution":{"iopub.status.busy":"2021-08-18T04:05:02.830009Z","iopub.execute_input":"2021-08-18T04:05:02.83028Z","iopub.status.idle":"2021-08-18T04:05:03.462489Z","shell.execute_reply.started":"2021-08-18T04:05:02.830254Z","shell.execute_reply":"2021-08-18T04:05:03.461431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns \n\nplt.style.use('fivethirtyeight')\n%config InlineBackend.figure_format = 'retina'\n%matplotlib inline\n\nsns.set(style = 'whitegrid')\nplt.title(\"Econ-wm1 Dataset\")\nsns.lineplot([i for i in range(len(value_lambda_1[0]))] , value_lambda_1[0],  label=\"lambda 1\")\nsns.lineplot([i for i in range(len(value_lambda_point8[0]))] , value_lambda_point8[0],  label=\"lambda 0.8\")\n \nplt.xlabel(\"No. of iterations\")\nplt.ylabel(\"Modularity Value\")\nplt.legend() \n# plt.show()\nplt.savefig(\"Econ_2.svg\")","metadata":{"execution":{"iopub.status.busy":"2021-08-18T04:05:03.46527Z","iopub.execute_input":"2021-08-18T04:05:03.465643Z","iopub.status.idle":"2021-08-18T04:05:04.096793Z","shell.execute_reply.started":"2021-08-18T04:05:03.465611Z","shell.execute_reply":"2021-08-18T04:05:04.095614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fb Food Dataset","metadata":{}},{"cell_type":"code","source":"import networkx as nx\nimport pandas as pd\n\nl1 = []\nl2 = []\nfile = open('../input/fbpagesfood/fb-pages-food.txt')\n\nfor line in file:\n    l1.append(int(line.split(',')[0]))\n    l2.append(int(line.split(',')[1]))\n\ndf = pd.DataFrame()\ndf[1] = l1\ndf[2] = l2\n\nG = nx.Graph()\nG = nx.from_pandas_edgelist(df, 1, 2)\n\nmapping  = {} \ni = 0\nfor node in G.nodes:\n    mapping[node] = i\n    i += 1\n    \n    \nG=nx.relabel_nodes(G,mapping)\n\nprint(nx.info(G))","metadata":{"execution":{"iopub.status.busy":"2021-08-18T04:16:52.637769Z","iopub.execute_input":"2021-08-18T04:16:52.63811Z","iopub.status.idle":"2021-08-18T04:16:52.677055Z","shell.execute_reply.started":"2021-08-18T04:16:52.638083Z","shell.execute_reply":"2021-08-18T04:16:52.676049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"part = community.best_partition(G)\ncommunity.modularity(part, G)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T04:16:58.76932Z","iopub.execute_input":"2021-08-18T04:16:58.769698Z","iopub.status.idle":"2021-08-18T04:16:58.897486Z","shell.execute_reply.started":"2021-08-18T04:16:58.769666Z","shell.execute_reply":"2021-08-18T04:16:58.896527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from random import choice\nimport random\nimport numpy as np\n\ntotalEdges = G.number_of_edges()\ntotalNodes= G.number_of_nodes()\nA = nx.to_numpy_array(G)\nS = np.array([(\"C\" + str(i)) for i in range(G.number_of_nodes())])\n\ninitial_S = np.array([(\"C\" + str(i)) for i in range(G.number_of_nodes())])\nnodesList = [node_k for node_k in range(G.number_of_nodes())]\n\nfrom numpy.random import choice\nprobabilities = [float(1/(G.number_of_nodes()*1.0)) for i in range(G.number_of_nodes())]\n\nvalue_lambda_point2 = communityDetect(S,G,nIter = 1000,LAMBDA = 0.2)\n\nprint('Partition Modularity = '+ str(partitionModularity(S,G)))","metadata":{"execution":{"iopub.status.busy":"2021-08-18T04:17:00.189117Z","iopub.execute_input":"2021-08-18T04:17:00.189681Z","iopub.status.idle":"2021-08-18T04:26:30.748905Z","shell.execute_reply.started":"2021-08-18T04:17:00.189632Z","shell.execute_reply":"2021-08-18T04:26:30.748024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom random import choice\nimport random\n\ntotalEdges = G.number_of_edges()\ntotalNodes= G.number_of_nodes()\nA = nx.to_numpy_array(G)\nS = np.array([(\"C\" + str(i)) for i in range(G.number_of_nodes())])\n\ninitial_S = np.array([(\"C\" + str(i)) for i in range(G.number_of_nodes())])\nnodesList = [node_k for node_k in range(G.number_of_nodes())]\n\nfrom numpy.random import choice\nprobabilities = [float(1/(G.number_of_nodes()*1.0)) for i in range(G.number_of_nodes())]\n\nvalue_lambda_point8 = communityDetect(S,G,nIter = 1000,LAMBDA = 0.8)\n\nprint('Partition Modularity = '+ str(partitionModularity(S,G)))","metadata":{"execution":{"iopub.status.busy":"2021-08-18T04:26:30.752578Z","iopub.execute_input":"2021-08-18T04:26:30.752861Z","iopub.status.idle":"2021-08-18T04:32:13.910059Z","shell.execute_reply.started":"2021-08-18T04:26:30.752832Z","shell.execute_reply":"2021-08-18T04:32:13.908939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from random import choice\nimport random\n\ntotalEdges = G.number_of_edges()\ntotalNodes= G.number_of_nodes()\nA = nx.to_numpy_array(G)\nS = np.array([(\"C\" + str(i)) for i in range(G.number_of_nodes())])\n\ninitial_S = np.array([(\"C\" + str(i)) for i in range(G.number_of_nodes())])\nnodesList = [node_k for node_k in range(G.number_of_nodes())]\n\nfrom numpy.random import choice\nprobabilities = [float(1/(G.number_of_nodes()*1.0)) for i in range(G.number_of_nodes())]\n\nvalue_lambda_1 = communityDetect(S,G,nIter = 1000,LAMBDA = 1)\n\nprint('Partition Modularity = '+ str(partitionModularity(S,G)))","metadata":{"execution":{"iopub.status.busy":"2021-08-18T04:32:13.911622Z","iopub.execute_input":"2021-08-18T04:32:13.912052Z","iopub.status.idle":"2021-08-18T04:45:17.094405Z","shell.execute_reply.started":"2021-08-18T04:32:13.91201Z","shell.execute_reply":"2021-08-18T04:45:17.093293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns \n\nplt.style.use('fivethirtyeight')\n%config InlineBackend.figure_format = 'retina'\n%matplotlib inline\n\nsns.set(style = 'whitegrid')\nplt.title(\"Fb-food Dataset\")\nsns.lineplot([i for i in range(len(value_lambda_point2[0]))] , value_lambda_point2[0],  label=\"lambda 0.2\")\nsns.lineplot([i for i in range(len(value_lambda_point8[0]))] , value_lambda_point8[0],  label=\"lambda 0.8\")\n \nplt.xlabel(\"No. of iterations\")\nplt.ylabel(\"Modularity Value\")\nplt.legend() \n# plt.show()\nplt.savefig(\"Fb-food_1.svg\")","metadata":{"execution":{"iopub.status.busy":"2021-08-18T04:45:17.095917Z","iopub.execute_input":"2021-08-18T04:45:17.09625Z","iopub.status.idle":"2021-08-18T04:45:17.833479Z","shell.execute_reply.started":"2021-08-18T04:45:17.09622Z","shell.execute_reply":"2021-08-18T04:45:17.832781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns \n\nplt.style.use('fivethirtyeight')\n%config InlineBackend.figure_format = 'retina'\n%matplotlib inline\n\nsns.set(style = 'whitegrid')\nplt.title(\"Fb-food Dataset\")\nsns.lineplot([i for i in range(len(value_lambda_1[0]))] , value_lambda_1[0],  label=\"lambda 1\")\nsns.lineplot([i for i in range(len(value_lambda_point8[0]))] , value_lambda_point8[0],  label=\"lambda 0.8\")\n \nplt.xlabel(\"No. of iterations\")\nplt.ylabel(\"Modularity Value\")\nplt.legend() \n# plt.show()\nplt.savefig(\"Fb-food_2.svg\")","metadata":{"execution":{"iopub.status.busy":"2021-08-18T04:45:17.83505Z","iopub.execute_input":"2021-08-18T04:45:17.835459Z","iopub.status.idle":"2021-08-18T04:45:18.560306Z","shell.execute_reply.started":"2021-08-18T04:45:17.83543Z","shell.execute_reply":"2021-08-18T04:45:18.559629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}